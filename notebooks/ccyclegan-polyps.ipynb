{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlI0dmYeXotw"
   },
   "source": [
    "# <font color='red'>**Data loader**</font>\n",
    "## **Useful libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1643123752262,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "OAZvBb8PaiBk"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2014,
     "status": "ok",
     "timestamp": 1643123754266,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "r3i3R3S8H54Z"
   },
   "outputs": [],
   "source": [
    "#TALE SECOND PART:\n",
    "class DataLoader():      \n",
    "    \n",
    "    \"\"\" Data loader method: loader initialization on training or test batch\n",
    "\n",
    "    Parameters\n",
    "    -------------------   \n",
    "    dataset_name: string- dataset name\n",
    "    img_res: array- image shape (n_rows, n_cols,n_channels)\n",
    "    path_csv: string- path csv (que contiene el csv?, es importante?***)\n",
    "    use_test_in_batch: boolean- decides if the data is test or not\n",
    "    normalize: boolean- for image normalization\n",
    "    \"\"\"\n",
    "    #csv dataset has three columns: Emotion: (label from 0 to 6)\n",
    "                              #   Pixels: (pixel values from 48X48 image)\n",
    "                              #   Usage: split to be used (train or test) \n",
    "    def __init__(self, dataset_name, img_res=(256, 256, 3), path_csv=None, use_test_in_batch=False, \n",
    "                 normalize=True):\n",
    "        \n",
    "        self.dataset_name = dataset_name\n",
    "        self.img_res = img_res\n",
    "        # images and labels vectors for train and test \n",
    "        self.img_vect_train = None \n",
    "        self.img_vect_test = None \n",
    "        self.lab_vect_train = None \n",
    "        self.lab_vect_test = None \n",
    "        self.path_csv = path_csv \n",
    "        ## labels dict\n",
    "        self.lab_dict = {0: \"Adenoma\", 1: \"Hyperplastic\" , 2: \"Serrated\"}\n",
    "        self.use_test_in_batch = use_test_in_batch\n",
    "        self.normalize = normalize \n",
    "        ## load dataset \n",
    "        self._load_internally()\n",
    "\n",
    "\n",
    "    def _load_internally(self):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        print(\">> loading \"+str(self.dataset_name)+\" ...\") \n",
    "        #reading csv dataset\n",
    "        if self.dataset_name == 'fer2013': #change dataset***\n",
    "            if self.path_csv is None:\n",
    "                raw_data = pd.read_csv('../ccycleGanCrc.csv', header=None)\n",
    "                raw_data.columns = [\"emotion\", \"pixels\", \"Usage\"]\n",
    "            else:\n",
    "                raw_data = pd.read_csv(self.path_csv)\n",
    "        else:\n",
    "            raise Exception(\"dataset not supported:\"+str(self.dataset_name))\n",
    "\n",
    "        #reading train and test split \n",
    "        n_train = np.sum(raw_data['Usage'] == 'Training')\n",
    "        n_test = np.sum(raw_data['Usage'] != 'Training')\n",
    "        assert n_train + n_test == len(raw_data)\n",
    "\n",
    "        #\"batch\" of training and test data (#train/test samples, img_w, img_h, img_ch, dataType)\n",
    "        self.img_vect_train = np.zeros( (n_train, self.img_res[0], self.img_res[1],\n",
    "                                         self.img_res[2]), 'float32')\n",
    "        self.img_vect_test = np.zeros( (n_test, self.img_res[0], self.img_res[1],\n",
    "                                        self.img_res[2]), 'float32')\n",
    "        self.lab_vect_train = np.zeros(n_train, 'int32')\n",
    "        self.lab_vect_test = np.zeros(n_test, 'int32')\n",
    "\n",
    "        i_train , i_test = 0,0\n",
    "        #pass throught all data\n",
    "        print(\"passing throught all data...\")\n",
    "        for i in range(len(raw_data)):\n",
    "            \n",
    "            #get pixels for i data\n",
    "            img = raw_data[\"pixels\"][i] \n",
    "            x_pixels = np.array(img.split(\" \"), 'float32')\n",
    "            #normalize\n",
    "            if self.normalize:\n",
    "                x_pixels = x_pixels/127.5 - 1.\n",
    "            #reshape into image matrix\n",
    "            x_pixels = x_pixels.reshape(self.img_res)\n",
    "            #get set (train or test)\n",
    "            us = raw_data[\"Usage\"][i]\n",
    "            #save into image vect set for training or test\n",
    "            if us == 'Training':            \n",
    "                self.img_vect_train[i_train] = x_pixels\n",
    "                self.lab_vect_train[i_train] = int(raw_data[\"emotion\"][i]) \n",
    "                i_train = i_train + 1\n",
    "            else:\n",
    "                self.img_vect_test[i_test] = x_pixels\n",
    "                self.lab_vect_test[i_test] = int(raw_data[\"emotion\"][i]) \n",
    "                i_test = i_test + 1\n",
    "\n",
    "        #for check \n",
    "        assert i_train == len(self.img_vect_train) \n",
    "        assert i_train == len(self.lab_vect_train) \n",
    "        assert i_test == len(self.lab_vect_test) \n",
    "        assert i_test == len(self.img_vect_test) \n",
    "\n",
    "        print(\"> loaded train:\",len(self.img_vect_train),\"   - test:\",len(self.lab_vect_test) )\n",
    "       \n",
    "        #when we use test data\n",
    "        print(\"info de use_test_in_batch: \", self.use_test_in_batch)\n",
    "        if self.use_test_in_batch:\n",
    "            #revisar por que no esta el metodo leo_lab\n",
    "            self.lab_vect_train = np.concatenate([self.lab_vect_train, self.lab_vect_test, self.leo_lab])\n",
    "            self.img_vect_train = np.concatenate([self.img_vect_train, self.img_vect_test, self.leo])\n",
    "\n",
    "    def load_leo(self):\n",
    "        \"\"\"Return label and image from reading\n",
    "        \"\"\"\n",
    "        return self.leo_lab , self.leo\n",
    "\n",
    "    def load_data(self, domain=None, batch_size=1, is_testing=False, convertRGB=False):\n",
    "        \"\"\"Load data function: load batch of data\n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "        domain: int- class label \n",
    "        batch_size: int- \n",
    "        is_testing: boolean- test or not\n",
    "        convertRGB: boolean- to make RGB images\n",
    "\n",
    "        Return\n",
    "        ------------\n",
    "        labels and images batch\n",
    "        \"\"\"\n",
    "        if is_testing:\n",
    "            #when label class was not given\n",
    "            if domain is None:\n",
    "                idx = np.random.choice(self.img_vect_test.shape[0], size=batch_size)\n",
    "            else:                \n",
    "                assert domain in [0,1,2,3,4,5,6]# for check that label given is correct\n",
    "                idx0 = np.argwhere(self.lab_vect_test == domain)#get shape of data with label to work \n",
    "                idx1 = np.random.choice(idx0.shape[0], size=batch_size)#random choice\n",
    "                idx = idx0[idx1]#from general data with the label we get the random data selected\n",
    "                idx = np.squeeze(idx)#check size dimensions of idx***\n",
    "            batch_images = self.img_vect_test[idx]\n",
    "            labels = self.lab_vect_test[idx]\n",
    "            #same for train data\n",
    "        else:\n",
    "            if domain is None:\n",
    "                idx = np.random.choice(self.lab_vect_train.shape[0],size=batch_size)\n",
    "            else:                \n",
    "                assert domain in [0,1,2,3,4,5,6]\n",
    "                idx0 = np.argwhere(self.lab_vect_train == domain) \n",
    "                idx1 = np.random.choice(idx0.shape[0],size=batch_size)\n",
    "                idx = idx0[idx1]\n",
    "                idx = np.squeeze(idx)\n",
    "            batch_images = self.img_vect_train[idx]\n",
    "            labels = self.lab_vect_train[idx]\n",
    "\n",
    "        batch_images = np.resize(batch_images, (batch_size, self.img_res[0], self.img_res[1],\n",
    "                                self.img_res[2]))\n",
    "\n",
    "        if convertRGB:            \n",
    "            _batch_images = np.zeros((batch_size, self.img_res[0], self.img_res[1], 3))\n",
    "            for i in range(batch_size):\n",
    "                _batch_images[i] = cv2.cvtColor(batch_images[i], cv2.COLOR_GRAY2RGB)\n",
    "            batch_images = _batch_images\n",
    "\n",
    "        if is_testing:\n",
    "            return labels , batch_images\n",
    "        for i in range(batch_size):\n",
    "            if np.random.random() > 0.5:#check its meaning***\n",
    "                batch_images[i] = np.fliplr(batch_images[i]) #for column flip (its needed?***)\n",
    "        return labels , batch_images\n",
    "\n",
    "    def load_batch(self, domain=None, batch_size=1, is_testing=False , convertRGB=False):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        --------------\n",
    "        domain: int- label class\n",
    "        batch_size: int- amount of images to be treated\n",
    "        is_testing: boolean- for testing pourposes\n",
    "        convertRGB: boolean- for get RGB images\n",
    "\n",
    "        Return:\n",
    "        --------------\n",
    "        labels and their respective batch images\n",
    "        \"\"\"\n",
    "        if is_testing:\n",
    "            raise Exception(\"not supported\")\n",
    "        self.n_batches = int(len(self.img_vect_train) / batch_size)\n",
    "        total_samples = self.n_batches * batch_size\n",
    "        for i in range(self.n_batches):                       \n",
    "            if domain is None:\n",
    "                idx = np.random.choice(self.lab_vect_train.shape[0], size=batch_size)\n",
    "            else:               \n",
    "                assert domain in list(range(7))\n",
    "                idx0 = np.argwhere(self.lab_vect_train == domain) \n",
    "                idx1 = np.random.choice(idx0.shape[0], size=batch_size)\n",
    "                idx = idx0[idx1]\n",
    "                idx = np.squeeze(idx)\n",
    "            batch_images = self.img_vect_train[idx]\n",
    "            labels = self.lab_vect_train[idx]\n",
    "            for i in range(batch_size):\n",
    "                if np.random.random() > 0.5:#check its meaning***\n",
    "                    batch_images[i] = np.fliplr(batch_images[i]) #for column flip (its needed?***)\n",
    "            batch_images = np.resize(batch_images, (batch_size,self.img_res[0],self.img_res[1],self.img_res[2]))\n",
    "            if convertRGB:\n",
    "                _batch_images = np.zeros((batch_size, self.img_res[0], self.img_res[1],3))\n",
    "                for i in range(batch_size):\n",
    "                    _batch_images[i] = cv2.cvtColor(batch_images[i], cv2.COLOR_GRAY2RGB)\n",
    "                batch_images = _batch_images\n",
    "            yield labels , batch_images\n",
    "\n",
    "            #Nota: no entiendo muy bien la diferencia entre los metodos load_batch y load_data***\n",
    "\n",
    "\n",
    "    def load_batch_AB(self, domain=None, batch_size=1, is_testing=False):\n",
    "        \"\"\"Load batch of data from two domains (A and B)\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        domain: array- labels class\n",
    "        batch_size: int- amount of data to be loaded\n",
    "        is_testing: boolean- for testing pourposes\n",
    "\n",
    "        Return:\n",
    "        ---------------\n",
    "        Batch images from domains A and B\n",
    "        Respective labels for data from both domains\n",
    "        \"\"\"\n",
    "        if is_testing:#it seems to no support testing (make is_testing=False always?***)\n",
    "            raise Exception(\"not supported\")\n",
    "        self.n_batches = int(len(self.img_vect_train) / batch_size)\n",
    "        total_samples = self.n_batches * batch_size\n",
    "        for i in range(self.n_batches):            \n",
    "            assert domain is not None #check if domain is not empty \n",
    "            assert type(domain) is list #domain type must be list format\n",
    "            #check both domains belong to labels between [0,6] \n",
    "            assert domain[0] in list(range(7))\n",
    "            assert domain[1] in list(range(7))\n",
    "            assert domain[0] != domain[1]#check different domains\n",
    "            domain_A , domain_B = domain[0] , domain[1]\n",
    "            # domain_A\n",
    "            idx0 = np.argwhere(self.lab_vect_train == domain_A) \n",
    "            idx1 = np.random.choice(idx0.shape[0],size=batch_size)\n",
    "            idx = idx0[idx1]\n",
    "            idx = np.squeeze(idx)\n",
    "            batch_images_A = self.img_vect_train[idx]\n",
    "            labels_A = self.lab_vect_train[idx]\n",
    "            for i in range(batch_size):\n",
    "                if np.random.random() > 10.5:#check its meaning***\n",
    "                    batch_images_A[i] = np.fliplr(batch_images_A[i])#for column flip (its needed?***)\n",
    "            batch_images_A = np.resize(batch_images_A, (batch_size,self.img_res[0],self.img_res[1],self.img_res[2]))\n",
    "            # domain_B\n",
    "            idx0 = np.argwhere(self.lab_vect_train == domain_B) \n",
    "            idx1 = np.random.choice(idx0.shape[0],size=batch_size)\n",
    "            idx = idx0[idx1]\n",
    "            idx = np.squeeze(idx)\n",
    "            batch_images_B = self.img_vect_train[idx]\n",
    "            labels_B = self.lab_vect_train[idx]\n",
    "            for i in range(batch_size):\n",
    "                if np.random.random() > 10.5:#check its meaning***\n",
    "                    batch_images_B[i] = np.fliplr(batch_images_B[i])#for column flip (its needed?***)\n",
    "            batch_images_B = np.resize(batch_images_B, (batch_size,self.img_res[0],self.img_res[1],self.img_res[2]))\n",
    "\n",
    "            yield labels_A , batch_images_A , labels_B , batch_images_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OILSfQzLMuF4"
   },
   "source": [
    "# <font color='red'>**Models**</font>\n",
    "## **Useful libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14168,
     "status": "ok",
     "timestamp": 1643123768425,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "2b61mo28GyG4",
    "outputId": "81e4cf6c-0e70-40bc-f7b5-96687406c07c"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6479,
     "status": "ok",
     "timestamp": 1643123774896,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "vD5nmW7xNH8J"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import Reshape\n",
    "import datetime\n",
    "import sys\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "import numpy as np\n",
    "import os\n",
    "import random \n",
    "from keras.layers import Conv2DTranspose, BatchNormalization\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZJrN2VnNf0g"
   },
   "source": [
    "### Useful methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1643123774900,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "OJ7FjahnNUdp"
   },
   "outputs": [],
   "source": [
    "def get_dim_conv(dim,f,p,s):\n",
    "    \"\"\"Function to calculate output conv shape\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dim: \n",
    "    f: int- amount of filters\n",
    "    p: int- padding\n",
    "    s: int- stride \n",
    "\n",
    "    Return:\n",
    "    -----------\n",
    "    new output dimension\n",
    "    \"\"\"\n",
    "    return int((dim+2*p-f)/2+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1643123775280,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "_nBAEgyrNptx"
   },
   "outputs": [],
   "source": [
    "def build_generator_enc_dec(img_shape, gf, num_classes, channels, num_layers=6, f_size=4, \n",
    "                            tranform_layer=False):\n",
    "    \"\"\"U-Net Generator\n",
    "    Parameters:\n",
    "    ------------\n",
    "    img_shape: array- image shape\n",
    "    gf: int- amount of filters check***\n",
    "    num_classes: int- classes to be taken into account\n",
    "    num_layers: int- number of layers in net\n",
    "    f_size: int- filter size\n",
    "    transform_layer: boolean- \n",
    "\n",
    "    Return: enconder and decoder nets\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def conv2d(layer_input, filters, f_size=f_size):\n",
    "        \"\"\"Layers used during downsampling\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=2, padding='valid')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        d = InstanceNormalization()(d)\n",
    "        return d    \n",
    "\n",
    "\n",
    "    def deconv2d(layer_input, skip_input, filters, f_size=f_size, dropout_rate=0, output_padding=None):\n",
    "        \"\"\"Layers used during upsampling\"\"\"\n",
    "\n",
    "        u = Conv2DTranspose(filters=filters, kernel_size=f_size, strides=2, activation='relu',\n",
    "                            output_padding=output_padding)(layer_input)\n",
    "\n",
    "        if dropout_rate:\n",
    "            u = Dropout(dropout_rate)(u)\n",
    "        u = InstanceNormalization()(u)\n",
    "        u = Concatenate()([u, skip_input])\n",
    "        return u\n",
    "\n",
    "    # Image input layer\n",
    "    img = Input(shape=img_shape)\n",
    "\n",
    "    # Downsampling\n",
    "    d = img \n",
    "    zs = [] \n",
    "    dims = []\n",
    "    _dim = img_shape[0]\n",
    "    for i in range(num_layers):\n",
    "        d = conv2d(d, gf*2**i)# add by 2 as we go deeper in the net\n",
    "        zs.append(d)\n",
    "        _dim = get_dim_conv(_dim,f_size,0,2)\n",
    "        dims.append((_dim,gf*2**i))\n",
    "        print(\"D:\",_dim,gf*2**i)\n",
    "\n",
    "    ######################## here is the problem (block section for new lines)\n",
    "    zs.pop()#remove last out: (2,2,2048)\n",
    "    d = MaxPool2D(pool_size=(2,2))(d)\n",
    "    zs.append(d)#add (1,1,2048)\n",
    "    ######################## final new lines\n",
    "    G_enc = Model(img,zs)#encoder net\n",
    "    print(\"*** generator enconder ok***!\")\n",
    "\n",
    "    _zs = [] \n",
    "    d_ , c_ = dims.pop()\n",
    "    i_ = Input(shape=(d_, d_, c_))\n",
    "    #two new lines\n",
    "    i_ = MaxPool2D(pool_size=(2,2))(i_)\n",
    "    _zs.append(i_)\n",
    "    label = Input(shape=(num_classes,), dtype='float32')\n",
    "    label_r = Reshape((1,1,num_classes))(label)\n",
    "\n",
    "    u = concatenate([i_, label_r],axis=-1)\n",
    "\n",
    "    ## transf (why?***)\n",
    "    if tranform_layer:\n",
    "        tr = Flatten()(u)\n",
    "        tr = Dense(c_+num_classes)(tr)\n",
    "        tr = LeakyReLU(alpha=0.2)(tr)\n",
    "        u = Reshape((1,1,c_+num_classes))(tr)\n",
    "    ##\n",
    "    u = Conv2D(c_, kernel_size=1, strides=1, padding='valid')(u) ## 1x1 conv \n",
    "\n",
    "    # Upsampling\n",
    "    for i in range(num_layers-1):\n",
    "        _ch = gf*2**((num_layers-2)-i)\n",
    "        d_ , c_ = dims.pop()\n",
    "        print(i,d_,c_)\n",
    "        i_ = Input(shape=(d_, d_, c_))\n",
    "        _zs.append(i_)\n",
    "        if i == 4:\n",
    "            u = Conv2DTranspose(filters=_ch, kernel_size=5, strides=2, activation='relu', \n",
    "                                output_padding=None)(u)\n",
    "\n",
    "            u = InstanceNormalization()(u)\n",
    "            u = Concatenate()([u, i_])\n",
    "        elif i==0:\n",
    "            u = Conv2DTranspose(filters=_ch, kernel_size=6, strides=2, activation='relu',\n",
    "                            output_padding=None)(u)\n",
    "\n",
    "            u = InstanceNormalization()(u)\n",
    "            u = Concatenate()([u, i_])\n",
    "\n",
    "        else:\n",
    "            u = deconv2d(u, i_, _ch)\n",
    "\n",
    "    u = Conv2DTranspose(filters=channels, kernel_size=f_size, strides=2, activation='tanh', output_padding=None)(u)\n",
    "\n",
    "\n",
    "    _zs.reverse()\n",
    "    _zs.append(label)\n",
    "    G_dec = Model(_zs,u) #decoder net\n",
    "\n",
    "    return G_enc , G_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape, df, num_classes, num_layers=6, act_multi_label='softmax'):\n",
    "    \"\"\"Build discriminator function: net for discriminate real from fake data\n",
    "      Parameters:\n",
    "      -----------\n",
    "      img_shape: array- (w,h,c)\n",
    "      df: int- dimension filters check***\n",
    "      num_layers: int- amount of model's layers\n",
    "      act_multi_label: string- activation function\n",
    "\n",
    "      Return: discriminator model\n",
    "      \"\"\"\n",
    "    \n",
    "\n",
    "    def d_layer(layer_input, filters, f_size=4, normalization=True):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=2, padding='valid')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if normalization:\n",
    "            d = InstanceNormalization()(d)\n",
    "        return d\n",
    "    \n",
    "    img = Input(shape=img_shape)\n",
    "\n",
    "    d = img \n",
    "    for i in range(num_layers):\n",
    "        #normalize all layers except the 1st one\n",
    "        _norm = False if i == 0 else True \n",
    "        filt = df*2**i\n",
    "        d = d_layer(d, filt, normalization=_norm)\n",
    "\n",
    "    d = MaxPool2D(pool_size=(2,2))(d)\n",
    "    flat_repr = Flatten()(d)#flat representation of the last layer\n",
    "\n",
    "    #validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "    print(\"flat_repr.get_shape().as_list():\",flat_repr.get_shape().as_list())\n",
    "    print(\"flat_repr.get_shape().as_list()[1:]:\",flat_repr.get_shape().as_list()[1:])\n",
    "\n",
    "    #Dense neural net\n",
    "    #Part to address the real or fake discrimination\n",
    "    gan_logit = Dense(df*2**(num_layers-1))(flat_repr)\n",
    "    gan_logit = LeakyReLU(alpha=0.2)(gan_logit)\n",
    "    gan_prob = Dense(1, activation='sigmoid')(gan_logit)\n",
    "\n",
    "    #Part to address the class classification\n",
    "    class_logit = Dense(df*2**(num_layers-1))(flat_repr)\n",
    "    class_logit = LeakyReLU(alpha=0.2)(class_logit)\n",
    "    class_prob = Dense(num_classes, activation=act_multi_label)(class_logit)\n",
    "\n",
    "\n",
    "    return Model(img, [gan_prob, class_prob])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyjrNuOyk_P9"
   },
   "source": [
    "# <font color='red'>**Conditional cycleGan network**</font>\n",
    "## **Useful libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1643123775581,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "RYDBsu4lXiT8"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, MaxPool2D\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.models import Sequential, Model\n",
    "#from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import Reshape\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "#from data_loader import DataLoader\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import random \n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import argparse\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#from  models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCycleGAN():\n",
    "    \"\"\" Conditional cycleGan: model initialization (generator and discriminator nets) and training,\n",
    "    receive image shape,\n",
    "    amount of classes to be taken into account, \n",
    "    weight losses for generator and discriminator nets,\n",
    "    load the dataset.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    img_rows and img_cols: int- rows and cols for image to work with\n",
    "    channels: int- amount of image channels\n",
    "    num_classes: int- amount of classes to be taken into account\n",
    "    d_gan_loss_w: int- discriminator loss weight\n",
    "    d_cl_loss_w: int- discriminator loss weight for class tag\n",
    "    g_gan_loss_w: int- generator loss weight\n",
    "    g_cl_loss_w: int- generator loss weight for class tag\n",
    "    ---> rec_loss_w: int- cycle consistency loss weight (check)\n",
    "    adam_lr: float- learning rate\n",
    "    adam_beta_1: float- parameters for adam rule\n",
    "    adam_beta_2: float- parameters for adam rule \n",
    "    \"\"\"\n",
    "\n",
    "    #values assignment\n",
    "    def __init__(self,img_rows = 256, img_cols = 256, channels = 3, num_classes=3, d_gan_loss_w=1,\n",
    "      d_cl_loss_w=1, g_gan_loss_w=1, g_cl_loss_w=1, rec_loss_w=1, adam_lr=0.0002, adam_beta_1=0.5,\n",
    "      adam_beta_2=0.999):\n",
    "        \n",
    "        # Input shape\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channels = channels\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Loss weights \n",
    "        self.d_gan_loss_w = d_gan_loss_w\n",
    "        self.d_cl_loss_w = d_cl_loss_w\n",
    "        self.g_gan_loss_w = g_gan_loss_w\n",
    "        self.g_cl_loss_w = g_cl_loss_w\n",
    "        self.rec_loss_w = rec_loss_w\n",
    "\n",
    "        # optmizer params \n",
    "        self.adam_lr = adam_lr\n",
    "        self.adam_beta_1 = adam_beta_1\n",
    "        self.adam_beta_2 = adam_beta_2\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'fer2013' #maybe changed dataset name (ver importancia del nombre?***)\n",
    "        # TALE SECOND PART (pasar a file: data_loader.py)\n",
    "        self.data_loader = DataLoader(dataset_name=self.dataset_name, img_res=self.img_shape,\n",
    "                                      use_test_in_batch=False)\n",
    "        # label dict\n",
    "        self.lab_dict = {0: \"Ade\", 1: \"Hyp\" , 2: \"Ser\"}\n",
    "\n",
    "        # Number of filters in the first layer of Generator and Discriminator\n",
    "        self.gf = 32\n",
    "        self.df = 64\n",
    "\n",
    "        optimizer = Adam(self.adam_lr, self.adam_beta_1, self.adam_beta_2) \n",
    "\n",
    "        # Build and compile the discriminators (models.py method)\n",
    "        self.d = build_discriminator(img_shape=self.img_shape, df=64, num_classes=self.num_classes,\n",
    "                                    act_multi_label='softmax')\n",
    "        print(\"******** Discriminator/Classifier ********\")\n",
    "        self.d.summary()\n",
    "        self.d.compile(loss=['binary_crossentropy',  # gan\n",
    "                             'binary_crossentropy'   # class\n",
    "                             ],\n",
    "                        optimizer=optimizer,\n",
    "                        metrics=['accuracy'],\n",
    "                        loss_weights=[\n",
    "                        self.d_gan_loss_w , # gan\n",
    "                        self.d_cl_loss_w   # class\n",
    "                        ])\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generators\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generators (here i go#1)\n",
    "        self.g_enc , self.g_dec = build_generator_enc_dec(img_shape=(256, 256, 3), gf=64, num_classes=3, \n",
    "                                                          channels=3, tranform_layer=True)\n",
    "        print(\"******** Generator_ENC ********\")\n",
    "        self.g_enc.summary()\n",
    "        print(\"******** Generator_DEC ********\")\n",
    "        self.g_dec.summary()\n",
    "\n",
    "        # Input images from both domains\n",
    "        print(\"***** images from domains *****\")\n",
    "        img = Input(shape=self.img_shape)\n",
    "        label0 = Input(shape=(self.num_classes,))\n",
    "        label1 = Input(shape=(self.num_classes,))\n",
    "\n",
    "        # Translate images to the other domain\n",
    "        z1,z2,z3,z4,z5,z6 = self.g_enc(img)\n",
    "        fake = self.g_dec([z1,z2,z3,z4,z5,z6,label1])\n",
    "\n",
    "        # Translate images back to original domain\n",
    "        reconstr = self.g_dec([z1,z2,z3,z4,z5,z6,label0])\n",
    "\n",
    "        # For the combined model we will only train the generators (why?)\n",
    "        self.d.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images gan_prob,\n",
    "        # class_prob [label,img], [gan_prob,class_prob]\n",
    "        gan_valid , class_valid = self.d(fake)\n",
    "\n",
    "        # Combined model trains generators to fool discriminators\n",
    "        self.combined = Model(inputs=[img,label0,label1], outputs=[ gan_valid, class_valid, reconstr])\n",
    "        self.combined.compile(loss=['binary_crossentropy','categorical_crossentropy', 'mae'],\n",
    "                              loss_weights=[                                      \n",
    "                                            self.g_gan_loss_w, # g_loss gan \n",
    "                                            self.g_cl_loss_w, # g_loss class  \n",
    "                                            self.rec_loss_w # reconstruction loss\n",
    "                                          ],\n",
    "                            optimizer=optimizer)\n",
    "\n",
    "        print(\"******** Combined model ********\")\n",
    "        self.combined.summary()\n",
    "\n",
    "    def generate_new_labels(self,labels0):\n",
    "        labels1 = [] \n",
    "        for i in range(len(labels0)):\n",
    "            allowed_values = list(range(0, self.num_classes))\n",
    "            allowed_values.remove(labels0[i])\n",
    "            labels1.append(random.choice(allowed_values))\n",
    "        return np.array(labels1,'int32')\n",
    "\n",
    "    def generate_new_labels_all(self, labels0):\n",
    "        #called from training procedure check***\n",
    "        \"\"\"Function for keep label values different from original labels\n",
    "        Parameter:\n",
    "        labels0: array- real label class list\n",
    "        Return: array with all labels different from original label class\n",
    "        \"\"\"\n",
    "        labels_all = [] \n",
    "        for i in range(len(labels0)):\n",
    "            allowed_values = list(range(0, self.num_classes))\n",
    "            allowed_values.remove(labels0[i])\n",
    "            labels_all.append(np.array(allowed_values,'int32'))\n",
    "        return np.array(labels_all,'int32')\n",
    "\n",
    "    def train(self, epochs, batch_size=1, sample_interval=50 , d_g_ratio=5):\n",
    "        \"\"\"Conditional cycleGan training function\n",
    "        Parameters:\n",
    "        ------------\n",
    "        epochs: int- amount of epochs to train model\n",
    "        batch_size: int- number of samples to be taken into account for each update step\n",
    "        sample_interval: int- check***\n",
    "        d_g_ratio: int- epoch frequency for decay learning rate check***\n",
    "        \"\"\"\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "        # logs \n",
    "        epoch_history, batch_i_history,  = [], []   \n",
    "        d_gan_loss_history, d_gan_accuracy_history, d_cl_loss_history, d_cl_accuracy_history = [], [], [], [] \n",
    "        g_gan_loss_history, g_cl_loss_history = [] , [] \n",
    "        reconstr_history = [] \n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,1) )\n",
    "        fake = np.zeros((batch_size,1) )\n",
    "\n",
    "        null_labels = np.zeros((batch_size,3) )\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (labels0 , imgs) in enumerate(self.data_loader.load_batch(batch_size=batch_size)):\n",
    "                labels1_all = self.generate_new_labels_all(labels0)\n",
    "\n",
    "                labels0_cat = to_categorical(labels0, num_classes=self.num_classes)\n",
    "                #\n",
    "                labels1_all_1 = to_categorical(labels1_all[:,0], num_classes=self.num_classes)\n",
    "                labels1_all_2 = to_categorical(labels1_all[:,1], num_classes=self.num_classes)\n",
    "\n",
    "                # ----------------------\n",
    "                #  Train Discriminators\n",
    "                # ----------------------\n",
    "\n",
    "                # Translate images to opposite domain\n",
    "                zs1,zs2,zs3,zs4,zs5,zs6 = self.g_enc.predict(imgs)#check what encoder returns***\n",
    "                fakes_1 = self.g_dec.predict([zs1,zs2,zs3,zs4,zs5,zs6,labels1_all_1])\n",
    "                fakes_2 = self.g_dec.predict([zs1,zs2,zs3,zs4,zs5,zs6,labels1_all_2])\n",
    "\n",
    "                # Train the discriminators (original images = real / translated = Fake)\n",
    "                idx = np.random.permutation(self.num_classes*labels0.shape[0])\n",
    "                _labels_cat = np.concatenate([labels0_cat,                                        \n",
    "                                              null_labels,\n",
    "                                              null_labels])\n",
    "                _imgs = np.concatenate([imgs,\n",
    "                                        fakes_1,\n",
    "                                        fakes_2])\n",
    "                \n",
    "                _vf = np.concatenate([valid, fake, fake])\n",
    "                _labels_cat = _labels_cat[idx]\n",
    "                _imgs = _imgs[idx]\n",
    "                _vf = _vf[idx]\n",
    "\n",
    "                d_loss  = self.d.train_on_batch(_imgs, [_vf,_labels_cat])\n",
    "\n",
    "                if batch_i % d_g_ratio == 0:\n",
    "                    # ------------------\n",
    "                    #  Train Generators\n",
    "                    # ------------------\n",
    "                    _imgs = np.concatenate([imgs,                                                     \n",
    "                                          imgs])\n",
    "\n",
    "                    _labels0_cat = np.concatenate([labels0_cat,                                                               \n",
    "                                                labels0_cat])\n",
    "\n",
    "                    _labels1_all_other = np.concatenate([labels1_all_1,                                                                                \n",
    "                                                      labels1_all_2])\n",
    "\n",
    "                    # I know this should be outside the loop;\n",
    "                    # left here to make code more understandable \n",
    "                    _valid = np.concatenate([valid,                                                 \n",
    "                                          valid])\n",
    "\n",
    "                    idx = np.random.permutation((self.num_classes-1)*labels0.shape[0])\n",
    "                    _imgs = _imgs[idx]\n",
    "                    _labels0_cat = _labels0_cat[idx]\n",
    "                    _labels1_all_other = _labels1_all_other[idx]\n",
    "                    _valid = _valid[idx]\n",
    "\n",
    "                    # Train the generators\n",
    "                    g_loss = self.combined.train_on_batch([_imgs, _labels0_cat, _labels1_all_other],\n",
    "                                                          [_valid, _labels1_all_other, _imgs])\n",
    "\n",
    "                    elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "                    print(\"[Epoch %d/%d] [Batch %d/%d] [D_gan loss: %f, acc_gan: %3d%%] [D_cl loss: %f, acc_cl: %3d%%] [G_gan loss: %05f, G_cl: %05f, recon: %05f] time: %s \" \\\n",
    "                      % ( epoch, epochs,\n",
    "                          batch_i, self.data_loader.n_batches,\n",
    "                          d_loss[1],100*d_loss[3],d_loss[2],100*d_loss[4],\n",
    "                          g_loss[1],g_loss[2],g_loss[3],\n",
    "                          elapsed_time))\n",
    "\n",
    "                    # log\n",
    "                    epoch_history.append(epoch) \n",
    "                    batch_i_history.append(batch_i)\n",
    "                    d_gan_loss_history.append(d_loss[1])\n",
    "                    d_gan_accuracy_history.append(100*d_loss[3])\n",
    "                    d_cl_loss_history.append(d_loss[2])\n",
    "                    d_cl_accuracy_history.append(100*d_loss[4])\n",
    "                    g_gan_loss_history.append(g_loss[1])\n",
    "                    g_cl_loss_history.append(g_loss[2])\n",
    "                    reconstr_history.append(g_loss[3])\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    self.sample_images(epoch, batch_i)\n",
    "                    #self.sample_images(epoch, batch_i,use_leo=True)\n",
    "\n",
    "                    train_history = pd.DataFrame({\n",
    "                        'epoch': epoch_history, \n",
    "                        'batch': batch_i_history, \n",
    "                        'd_gan_loss': d_gan_loss_history, \n",
    "                        'd_gan_accuracy' : d_gan_accuracy_history,\n",
    "                        'd_cl_loss': d_cl_loss_history, \n",
    "                        'd_cl_accuracy': d_cl_accuracy_history, \n",
    "                        'g_gan_loss': g_gan_loss_history, \n",
    "                        'g_cl_loss': g_cl_loss_history, \n",
    "                        'reconstr_loss': reconstr_history\n",
    "                    })\n",
    "                    train_history.to_csv(str(sys.argv[0]).split('.')[0]+'_train_log.csv',index=False)\n",
    "                    \n",
    "                    #new lines\n",
    "                    file_name = '../checkPoints/batch' + str(batch_i) + '.h5'\n",
    "                    self.combined.save(file_name)\n",
    "                    print(\"model saved!\")\n",
    "                    \n",
    "\n",
    "    def sample_images(self, epoch, batch_i, use_leo=False):\n",
    "        \"\"\"Function to save a batch test samples\n",
    "        Parameters:\n",
    "        ------------\n",
    "        epoch: int- epoch where the interval save is done\n",
    "        batch_i: int- number of batch where we want to save\n",
    "        \"\"\"\n",
    "        ## disc\n",
    "        labels0_d , imgs_d = self.data_loader.load_data(batch_size=64, is_testing=True)\n",
    "        #predicting images with discriminator net\n",
    "        gan_pred_prob, class_pred_prob = self.d.predict(imgs_d)\n",
    "\n",
    "        gan_pred = (gan_pred_prob > 0.5)*1.0\n",
    "        gan_pred = gan_pred.reshape((64,))\n",
    "\n",
    "        class_pred = np.argmax(class_pred_prob,axis=1)\n",
    "\n",
    "        gan_test_accuracy = accuracy_score(y_true=np.ones(64), y_pred=gan_pred)\n",
    "        class_test_accuracy = accuracy_score(y_true=labels0_d, y_pred=class_pred)\n",
    "\n",
    "        print(\"*** TEST *** [D_gan accuracy :\",gan_test_accuracy,\"] [D_cl accuracy :\", class_test_accuracy,\"]\")\n",
    "\n",
    "        ## gen         \n",
    "        if use_leo:\n",
    "            labels0_ , imgs_ = self.data_loader.load_leo()#load_leo() why?***\n",
    "        else:\n",
    "            labels0_ , imgs_ = self.data_loader.load_data(batch_size=1, is_testing=True)\n",
    "        labels1_all = self.generate_new_labels_all(labels0_)\n",
    "\n",
    "        labels0_cat = to_categorical(labels0_, num_classes=self.num_classes)\n",
    "        labels1_all_1 = to_categorical(labels1_all[:,0], num_classes=self.num_classes)\n",
    "        labels1_all_2 = to_categorical(labels1_all[:,1], num_classes=self.num_classes)\n",
    "        \n",
    "        # Translate images \n",
    "        zs1_,zs2_,zs3_,zs4_, zs5_, zs6_ = self.g_enc.predict(imgs_)\n",
    "        fake_1 = self.g_dec.predict([zs1_,zs2_,zs3_,zs4_,zs5_,zs6_,labels1_all_1])\n",
    "        fake_2 = self.g_dec.predict([zs1_,zs2_,zs3_,zs4_,zs5_,zs6_,labels1_all_2])\n",
    "\n",
    "        # Reconstruct image \n",
    "        reconstr_ = self.g_dec.predict([zs1_,zs2_,zs3_,zs4_,zs5_,zs6_,labels0_cat])\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_,                              \n",
    "                                  fake_1, \n",
    "                                  fake_2,\n",
    "                                  reconstr_])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5# check the rol of 0.5***\n",
    "\n",
    "        titles = ['Orig:'+str(self.lab_dict[labels0_.item(0)]), \n",
    "                  'Trans:'+str(self.lab_dict[labels1_all[:,0].item(0)]),\n",
    "                  'Trans:'+str(self.lab_dict[labels1_all[:,1].item(0)]),\n",
    "                  'Reconstr.']\n",
    "        r, c = 1, 4#for rows and cols\n",
    "        fig, axs = plt.subplots(r, c, figsize=(16,16), squeeze=False)\n",
    "\n",
    "        plt.subplots_adjust(hspace=0)\n",
    "\n",
    "        if not os.path.exists( \"images/%s/\"% (self.dataset_name)):\n",
    "            os.makedirs( \"images/%s/\"% (self.dataset_name)  )\n",
    "\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                imagen = gen_imgs[cnt]\n",
    "                #imagen = imagen.reshape(self.img_rows, self.img_cols, self.channels)\n",
    "                #print(\"reshape correcto!\")\n",
    "                axs[i,j].imshow(imagen)\n",
    "                axs[i,j].set_title(titles[cnt])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "\n",
    "        if use_leo:\n",
    "            fig.savefig(\"images/%s/%d_%d_leo.png\" % (self.dataset_name, epoch, batch_i))\n",
    "        else:\n",
    "            fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPPr9fC3TaL4"
   },
   "source": [
    "# <font color='red'>Main</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1643123776733,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "e5c-ISS1TEFe"
   },
   "outputs": [],
   "source": [
    "d_gan_loss_w =1\n",
    "d_cl_loss_w =1\n",
    "g_gan_loss_w =2\n",
    "g_cl_loss_w =2\n",
    "rec_loss_w =1\n",
    "adam_lr =0.0002\n",
    "adam_beta_1 =0.5\n",
    "adam_beta_2 =0.999\n",
    "epochs =170\n",
    "batch_size =8\n",
    "sample_interval =200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37240,
     "status": "ok",
     "timestamp": 1643123813966,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "xUZw1qOLUsZz",
    "outputId": "807f9191-0837-449e-c3c9-874c4b77a2a5"
   },
   "outputs": [],
   "source": [
    "# CCycleGAN: THE TALE START HERE\n",
    "gan = CCycleGAN(d_gan_loss_w=d_gan_loss_w, d_cl_loss_w=d_cl_loss_w,            \n",
    "                g_gan_loss_w=g_gan_loss_w, g_cl_loss_w=g_cl_loss_w,\n",
    "                rec_loss_w=rec_loss_w, adam_lr=adam_lr,\n",
    "                adam_beta_1=adam_beta_1, adam_beta_2=adam_beta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2gXVL0y9w46S",
    "outputId": "ef5ec0c4-0c37-4a79-a5f4-34a997fd09e5"
   },
   "outputs": [],
   "source": [
    "gan.train(epochs=epochs, batch_size=batch_size, sample_interval=sample_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMYU9J8CYA5kC7tZ90qyqgf",
   "collapsed_sections": [],
   "mount_file_id": "1auNkyV1smaOcPqNmjHH4VimSQFzugP2C",
   "name": "ccyclegan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
